name: Lightspeed Core Service (LCS)
service:
  host: 0.0.0.0
  port: 8443
  tls_config:
    tls_certificate_path: "/opt/app-root/certs/tls.crt"
    tls_key_path: "/opt/app-root/certs/tls.key"
  auth_enabled: false
  workers: 1
  color_log: true
  access_log: true
llama_stack:
  use_as_library_client: true
  library_client_config_path: /opt/app-root/run.yaml
user_data_collection:
  feedback_enabled: true
  feedback_storage: "/tmp/data/feedback"
  transcripts_enabled: true
  transcripts_storage: "/tmp/data/transcripts"
authentication:
  module: "noop"
conversation_cache:
  type: "sqlite"
  sqlite:
    db_path: "/tmp/data/conversation-cache.db"
inference:
  default_model: gpt-4o-mini
  default_provider: openai
mcp_servers:
  - name: "obs"
    provider_id: "model-context-protocol"
    url: "http://genie-obs-mcp-server:8085/mcp"
    authorization_headers:
      Authorization: "kubernetes"    # Uses user's k8s token from request auth
  - name: "kube"
    provider_id: "model-context-protocol"
    url: "http://mcp-kubernetes-svc:80/mcp"
    authorization_headers:
      Authorization: "kubernetes"    # Uses user's k8s token from request auth
  - name: "ngui"
    provider_id: "model-context-protocol"
    url: "http://ngui-mcp:9200/mcp"
    authorization_headers:
      Authorization: "kubernetes"    # Uses user's k8s token from request auth
customization:
  system_prompt: |-
    Always use available tools.
